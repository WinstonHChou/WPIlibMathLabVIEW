<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML>
<!-- Constructed with LabVIEW Report Generation -->
<HEAD>
<TITLE></TITLE>
</HEAD>

<BODY>
<h2 id="DiffDrivePoseEst2" >DiffDrivePoseEst2</h2>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_AddVisionMeasurement" >DiffDrivePoseEst2_AddVisionMeasurement</h3>
<p><IMG SRC="DiffDrivePoseEst2_AddVisionMeasurement_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Add a vision measurement to the Unscented Kalman Filter. This will correct the odometry pose estimate while still accounting for measurement noise.<BR>
   <BR>
This method can be called as infrequently as you want, as long as you are calling DifferentialDrivePoseEstimator_update every loop.<BR>
<BR>
To promote stability of the pose estimate and make it robust to bad vision data, we recommend only adding vision measurements that are already within one meter or so of the current pose estimate.<BR>
<BR>
   Inputs:<BR>
  -  InDIffDrivePoseEstimate  --  Data cluster for this system<BR>
  -  visionRobotPoseMeters  --  The pose of the robot as measured by the vision camera.<BR>
  -  timestampSeconds  --  The timestamp of the vision measurement in seconds. Note that if you don't use your own time source by calling DifferentialDrivePoseEstimator_updateWithTime then you must use a timestamp with an epoch since FPGA startup (i.e. the epoch of this timestamp is the same epoch as Timer.getFPGATimestamp.) This means that you should use Timer.getFPGATimestamp as your time source in this case.<BR>
<BR>
Outputs:<BR>
  -  OutDIffDrivePoseEstimate  --  Data cluster for this system<BR>
  -  Error  --  Returns TRUE if an error occured.  <BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_BufferDuration" >DiffDrivePoseEst2_BufferDuration</h3>
<p><IMG SRC="DiffDrivePoseEst2_BufferDuration_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Gets the pose of the robot at the current time as estimated by the Unscented Kalman Filter.<BR>
   <BR>
Inputs:<BR>
  -  DiffDrivePoseEst  -  System data cluster<BR>
<BR>
Outputs:<BR>
  -  EstimatedPose  -  The estimated robot pose in meters.<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_GetEstimatedPosition" >DiffDrivePoseEst2_GetEstimatedPosition</h3>
<p><IMG SRC="DiffDrivePoseEst2_GetEstimatedPosition_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Gets the pose of the robot at the current time as estimated by the Unscented Kalman Filter.<BR>
   <BR>
Inputs:<BR>
  -  DiffDrivePoseEst  -  System data cluster<BR>
<BR>
Outputs:<BR>
  -  EstimatedPose  -  The estimated robot pose in meters.<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_InterpRecord_ExtractFromVar" >DiffDrivePoseEst2_InterpRecord_ExtractFromVar</h3>
<p><IMG SRC="DiffDrivePoseEst2_InterpRecord_ExtractFromVar_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;"></pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_InterpRecord_Interp" >DiffDrivePoseEst2_InterpRecord_Interp</h3>
<p><IMG SRC="DiffDrivePoseEst2_InterpRecord_Interp_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;"></pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_InterpRecord_New" >DiffDrivePoseEst2_InterpRecord_New</h3>
<p><IMG SRC="DiffDrivePoseEst2_InterpRecord_New_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;"></pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_New" >DiffDrivePoseEst2_New</h3>
<p><IMG SRC="DiffDrivePoseEst2_New_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">This class wraps Differential Drive Odometry to fuse latency-compensated vision measurements with differential drive encoder measurements. It is intended to be a drop-in replacement for DiffDrvOdom2; in fact, if you never call DiffDrvPoseEst2_AddVisionMeasurement and only call  DiffDrvPoseEst2_Update then this will behave exactly the same as DiffDrvOdom2.<BR>
 <BR>
DiffDrvPoseEst2_Update should be called every robot loop.<BR>
 <BR>
DiffDrvPoseEst2_AddVisionMeasurement can be called as infrequently as you want.  If you never call it then this set of VI will behave exactly like regular encoder odometry.<BR>
<BR>
Constructs a DifferentialDrivePoseEstimator.<BR>
<BR>
The default standard deviations of the model states are 0.02 meters for x, 0.02 meters for y, and 0.01 radians for heading. The default standard deviations of the vision measurements are 0.1 meters for x, 0.1 meters for y, and 0.1 radians for heading.<BR>
<BR>
Inputs:   <BR>
  -  kinematics  --  DiffDriveKinematics  --  A correctly-configured kinematics data cluster for your drivetrain.<BR>
  -  gyroAngle  --  Rotation2d  --  The current gyro angle.<BR>
  -  leftDistanceMeters  -- double  --  The distance traveled by the left encoder.<BR>
  -  rightDistanceMeters  --  double  --  The distance traveled by the right encoder.<BR>
  -  initialPoseMeters  --  Pose2d  --  The starting pose estimate.<BR>
  -  stateStdDevs  --  <3,1> matrix  --  Standard deviations of the pose estimate (x position in meters, y position in meters, and heading in radians). Increase these numbers to trust your state estimate less.<BR>
  -  visionMeasurementStdDevs  -- <3,1> matrix  --  Standard deviations of the vision pose measurement (x position in meters, y position in meters, and heading in radians). Increase these numbers to trust the vision pose measurement less.<BR>
   <BR>
Outputs:<BR>
  --  DiffDrivePoseEst2  -- DiffDrivePoseEst2  -- Created data cluster.<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_ResetPosition" >DiffDrivePoseEst2_ResetPosition</h3>
<p><IMG SRC="DiffDrivePoseEst2_ResetPosition_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Resets the robot's position on the field.<BR>
   <BR>
The gyroscope angle does not need to be reset here on the user's robot code. The library automatically takes care of offsetting the gyro angle.<BR>
   <BR>
Inputs:<BR>
  - inDiffDrvPoseEst2  -- DifDrvPoseEst2  -- Data cluster<BR>
  -  gyroAngle  --  Rotation2d  --  The angle reported by the gyroscope.<BR>
  -  leftPositionMeters  -- double  --  The distance traveled by the left encoder.<BR>
  -  rightPositionMeters  -- double  --  The distance traveled by the right encoder.<BR>
  -  poseMeters  --  Pose2d  --  The position on the field that your robot is at.<BR>
<BR>
Outputs:<BR>
  - outDiffDrvPoseEst2  -- DifDrvPoseEst2  -- Updated data cluster<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_SetVisionMeasurementStdDevs" >DiffDrivePoseEst2_SetVisionMeasurementStdDevs</h3>
<p><IMG SRC="DiffDrivePoseEst2_SetVisionMeasurementStdDevs_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Sets the pose estimator's trust of global measurements. This might be used to change trust in vision measurements after the autonomous period, or to change trust as distance to a vision target increases.<BR>
   <BR>
Inputs:<BR>
  - inDiffDrvPoseEst2  -- DifDrvPoseEst2  -- Data cluster<BR>
  - VisionMeasurementStdDevs  -- <3,1> Matrix  --  Standard deviations of the vision measurements.  Increase these numbers to trust global measurements from vision less. This matrix is in the form [x, y, theta]Time, with units in meters and radians.<BR>
<BR>
Outputs:<BR>
  - outDiffDrvPoseEst2  -- DifDrvPoseEst2  -- Updated data cluster<BR>
  - sizeCooerced  -- boolean -- If TRUE, then the size of the vision measurement standard deviations was not 3,1.  The size was modified to allow this routine to complete.<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_Update" >DiffDrivePoseEst2_Update</h3>
<p><IMG SRC="DiffDrivePoseEst2_Update_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Updates the the Unscented Kalman Filter using only wheel encoder information. Note that this should be called every loop.<BR>
<BR>
Inputs:<BR>
  -  LeftSpeed  -- Left wheel speed (meters/sec)<BR>
  -  RightSpeed  -- Right wheel speed (meters/sec)<BR>
  -  inDiffDrivePoseEst  --  system data cluster<BR>
  -  gyroAngle  --  The current gyro angle.  (radians)<BR>
  -  distanceLeftMeters  --  The total distance travelled by the left wheel in meters.  This can be the encoder reading.<BR>
  -  distanceRightMeters  --  The total distance travelled by the right wheel in meters.   This can be the encoder reading.<BR>
<BR>
Outputs:<BR>
  -  outDiffDrivePoseEst  --  system data cluster<BR>
  -  EstimatedPose  -- The estimated pose of the robot in meters.<BR>
<BR>
</pre></p>
<br>
<HR SIZE="6" WIDTH=" 100.000000%" COLOR="GREY">
<h3 id="DiffDrivePoseEst2_UpdateWithTime" >DiffDrivePoseEst2_UpdateWithTime</h3>
<p><IMG SRC="DiffDrivePoseEst2_UpdateWithTime_iconc.png"  ALIGN=BOTTOM></p>
<p><pre style="overflow-x: auto; white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word; font-family: serif; font-size: 12pt;">Updates the the Unscented Kalman Filter using only wheel encoder information. Note that this should be called every loop.<BR>
<BR>
Inputs:<BR>
  -  LeftSpeed  -- Left wheel speed (meters/sec)<BR>
  -  RightSpeed  -- Right wheel speed (meters/sec)<BR>
  -  inDiffDrivePoseEst  --  system data cluster<BR>
  -  gyroAngle  --  The current gyro angle.  (radians)<BR>
  -  currentTime  --  Time at which this method was called, in seconds.<BR>
  -  distanceLeftMeters  --  The total distance travelled by the left wheel in meters.  This can be the encoder reading.<BR>
  -  distanceRightMeters  --  The total distance travelled by the right wheel in meters.   This can be the encoder reading.<BR>
<BR>
Outputs:<BR>
  -  outDiffDrivePoseEst  --  system data cluster<BR>
  -  EstimatedPose  -- The estimated pose of the robot in meters.<BR>
<BR>
</pre></p>
<br>
</BODY>
</HTML>